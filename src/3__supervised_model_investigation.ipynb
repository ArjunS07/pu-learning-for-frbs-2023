{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score, fbeta_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import warnings\n",
    "\n",
    "import optuna\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from utils import get_subburst_preserved_train_test, lee_liu_score\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tns_name</th>\n",
       "      <th>repeater_name</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>gl</th>\n",
       "      <th>gb</th>\n",
       "      <th>exp_up</th>\n",
       "      <th>exp_low</th>\n",
       "      <th>bonsai_snr</th>\n",
       "      <th>bonsai_dm</th>\n",
       "      <th>snr_fitb</th>\n",
       "      <th>dm_fitb</th>\n",
       "      <th>dm_exc_ne2001</th>\n",
       "      <th>dm_exc_ymw16</th>\n",
       "      <th>bc_width</th>\n",
       "      <th>scat_time</th>\n",
       "      <th>flux</th>\n",
       "      <th>fluence</th>\n",
       "      <th>sub_num</th>\n",
       "      <th>width_fitb</th>\n",
       "      <th>sp_idx</th>\n",
       "      <th>sp_run</th>\n",
       "      <th>high_freq</th>\n",
       "      <th>low_freq</th>\n",
       "      <th>peak_freq</th>\n",
       "      <th>chi_sq</th>\n",
       "      <th>dof</th>\n",
       "      <th>flag_frac</th>\n",
       "      <th>is_repeater</th>\n",
       "      <th>is_pcc_candidate</th>\n",
       "      <th>catalog</th>\n",
       "      <th>redshift</th>\n",
       "      <th>fre_width</th>\n",
       "      <th>fre_width_ob</th>\n",
       "      <th>in_duration</th>\n",
       "      <th>energy</th>\n",
       "      <th>luminosity</th>\n",
       "      <th>T_B</th>\n",
       "      <th>log_dm_fitb</th>\n",
       "      <th>log_bonsai_dm</th>\n",
       "      <th>log_dm_exc_ne2001</th>\n",
       "      <th>log_dm_exc_ymw16</th>\n",
       "      <th>log_bc_width</th>\n",
       "      <th>log_scat_time</th>\n",
       "      <th>log_flux</th>\n",
       "      <th>log_fluence</th>\n",
       "      <th>log_width_fitb</th>\n",
       "      <th>log_high_freq</th>\n",
       "      <th>log_low_freq</th>\n",
       "      <th>log_peak_freq</th>\n",
       "      <th>log_fre_width</th>\n",
       "      <th>log_redshift</th>\n",
       "      <th>log_in_duration</th>\n",
       "      <th>log_energy</th>\n",
       "      <th>log_luminosity</th>\n",
       "      <th>log_T_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FRB20180725A</td>\n",
       "      <td>-9999</td>\n",
       "      <td>93.420</td>\n",
       "      <td>67.070</td>\n",
       "      <td>147.29</td>\n",
       "      <td>21.29</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>19.20</td>\n",
       "      <td>716.6</td>\n",
       "      <td>33.20</td>\n",
       "      <td>715.80930</td>\n",
       "      <td>644.2</td>\n",
       "      <td>635.4</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.70</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>38.20</td>\n",
       "      <td>-45.80</td>\n",
       "      <td>760.1</td>\n",
       "      <td>485.3</td>\n",
       "      <td>607.4</td>\n",
       "      <td>371857.954</td>\n",
       "      <td>371481</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.640740</td>\n",
       "      <td>450.875425</td>\n",
       "      <td>274.8</td>\n",
       "      <td>0.180406</td>\n",
       "      <td>2.827944e+40</td>\n",
       "      <td>1.923870e+43</td>\n",
       "      <td>5.515622e+35</td>\n",
       "      <td>2.854797</td>\n",
       "      <td>2.855277</td>\n",
       "      <td>2.809021</td>\n",
       "      <td>2.803047</td>\n",
       "      <td>-2.530178</td>\n",
       "      <td>-2.958607</td>\n",
       "      <td>0.230449</td>\n",
       "      <td>0.612784</td>\n",
       "      <td>-3.528708</td>\n",
       "      <td>2.880871</td>\n",
       "      <td>2.686010</td>\n",
       "      <td>2.783475</td>\n",
       "      <td>2.654057</td>\n",
       "      <td>-0.193318</td>\n",
       "      <td>-0.743748</td>\n",
       "      <td>40.451471</td>\n",
       "      <td>43.284176</td>\n",
       "      <td>35.741595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FRB20180727A</td>\n",
       "      <td>-9999</td>\n",
       "      <td>197.720</td>\n",
       "      <td>26.420</td>\n",
       "      <td>24.76</td>\n",
       "      <td>85.60</td>\n",
       "      <td>10.4</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>10.40</td>\n",
       "      <td>642.1</td>\n",
       "      <td>12.20</td>\n",
       "      <td>642.13400</td>\n",
       "      <td>620.9</td>\n",
       "      <td>622.4</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>3.80</td>\n",
       "      <td>-9.20</td>\n",
       "      <td>800.2</td>\n",
       "      <td>400.2</td>\n",
       "      <td>493.3</td>\n",
       "      <td>382969.318</td>\n",
       "      <td>381818</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.614818</td>\n",
       "      <td>645.927163</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.860778</td>\n",
       "      <td>1.189571e+40</td>\n",
       "      <td>4.823143e+42</td>\n",
       "      <td>2.622746e+35</td>\n",
       "      <td>2.807626</td>\n",
       "      <td>2.807603</td>\n",
       "      <td>2.793022</td>\n",
       "      <td>2.794070</td>\n",
       "      <td>-2.530178</td>\n",
       "      <td>-2.769551</td>\n",
       "      <td>-0.236572</td>\n",
       "      <td>0.363612</td>\n",
       "      <td>-2.856985</td>\n",
       "      <td>2.903199</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.693111</td>\n",
       "      <td>2.810184</td>\n",
       "      <td>-0.211253</td>\n",
       "      <td>-0.065109</td>\n",
       "      <td>40.075391</td>\n",
       "      <td>42.683330</td>\n",
       "      <td>35.418756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FRB20180729A</td>\n",
       "      <td>-9999</td>\n",
       "      <td>199.400</td>\n",
       "      <td>55.580</td>\n",
       "      <td>115.26</td>\n",
       "      <td>61.16</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>108.4</td>\n",
       "      <td>206.60</td>\n",
       "      <td>109.59418</td>\n",
       "      <td>78.8</td>\n",
       "      <td>86.8</td>\n",
       "      <td>0.00098</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>11.70</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>16.46</td>\n",
       "      <td>-30.21</td>\n",
       "      <td>692.7</td>\n",
       "      <td>400.2</td>\n",
       "      <td>525.6</td>\n",
       "      <td>264732.041</td>\n",
       "      <td>186953</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>293.157605</td>\n",
       "      <td>292.5</td>\n",
       "      <td>0.099776</td>\n",
       "      <td>1.070358e+36</td>\n",
       "      <td>7.383140e+38</td>\n",
       "      <td>4.845901e+32</td>\n",
       "      <td>2.039787</td>\n",
       "      <td>2.035029</td>\n",
       "      <td>1.896526</td>\n",
       "      <td>1.938520</td>\n",
       "      <td>-3.008774</td>\n",
       "      <td>-3.802995</td>\n",
       "      <td>1.068186</td>\n",
       "      <td>1.230449</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>2.840545</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.720655</td>\n",
       "      <td>2.467101</td>\n",
       "      <td>-2.648161</td>\n",
       "      <td>-1.000975</td>\n",
       "      <td>36.029529</td>\n",
       "      <td>38.868241</td>\n",
       "      <td>32.685375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FRB20180729B</td>\n",
       "      <td>-9999</td>\n",
       "      <td>89.930</td>\n",
       "      <td>56.500</td>\n",
       "      <td>156.90</td>\n",
       "      <td>15.68</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>12.40</td>\n",
       "      <td>318.6</td>\n",
       "      <td>22.00</td>\n",
       "      <td>317.22350</td>\n",
       "      <td>223.2</td>\n",
       "      <td>198.8</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>14.50</td>\n",
       "      <td>-14.60</td>\n",
       "      <td>800.2</td>\n",
       "      <td>441.8</td>\n",
       "      <td>657.5</td>\n",
       "      <td>425139.488</td>\n",
       "      <td>421337</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.157566</td>\n",
       "      <td>414.871625</td>\n",
       "      <td>358.4</td>\n",
       "      <td>0.271259</td>\n",
       "      <td>4.966122e+38</td>\n",
       "      <td>4.407270e+41</td>\n",
       "      <td>3.166148e+34</td>\n",
       "      <td>2.501365</td>\n",
       "      <td>2.503246</td>\n",
       "      <td>2.348694</td>\n",
       "      <td>2.298416</td>\n",
       "      <td>-2.705534</td>\n",
       "      <td>-3.180456</td>\n",
       "      <td>-0.036212</td>\n",
       "      <td>0.079181</td>\n",
       "      <td>-3.503070</td>\n",
       "      <td>2.903199</td>\n",
       "      <td>2.645226</td>\n",
       "      <td>2.817896</td>\n",
       "      <td>2.617914</td>\n",
       "      <td>-0.802538</td>\n",
       "      <td>-0.566616</td>\n",
       "      <td>38.696017</td>\n",
       "      <td>41.644170</td>\n",
       "      <td>34.500531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FRB20180730A</td>\n",
       "      <td>-9999</td>\n",
       "      <td>57.390</td>\n",
       "      <td>87.190</td>\n",
       "      <td>125.11</td>\n",
       "      <td>25.11</td>\n",
       "      <td>270.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>69.50</td>\n",
       "      <td>849.2</td>\n",
       "      <td>89.80</td>\n",
       "      <td>848.90410</td>\n",
       "      <td>789.7</td>\n",
       "      <td>790.5</td>\n",
       "      <td>0.00492</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>5.20</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>4.27</td>\n",
       "      <td>-11.31</td>\n",
       "      <td>759.2</td>\n",
       "      <td>400.2</td>\n",
       "      <td>483.5</td>\n",
       "      <td>429165.844</td>\n",
       "      <td>417689</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.802405</td>\n",
       "      <td>647.063272</td>\n",
       "      <td>359.0</td>\n",
       "      <td>0.259653</td>\n",
       "      <td>2.335510e+41</td>\n",
       "      <td>8.107252e+43</td>\n",
       "      <td>1.508095e+36</td>\n",
       "      <td>2.928859</td>\n",
       "      <td>2.929010</td>\n",
       "      <td>2.897462</td>\n",
       "      <td>2.897902</td>\n",
       "      <td>-2.308035</td>\n",
       "      <td>-2.683401</td>\n",
       "      <td>0.716003</td>\n",
       "      <td>1.431364</td>\n",
       "      <td>-3.329754</td>\n",
       "      <td>2.880356</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.684396</td>\n",
       "      <td>2.810947</td>\n",
       "      <td>-0.095607</td>\n",
       "      <td>-0.585606</td>\n",
       "      <td>41.368382</td>\n",
       "      <td>43.908874</td>\n",
       "      <td>36.178429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>FRB20210313E</td>\n",
       "      <td>FRB20201221B</td>\n",
       "      <td>124.199</td>\n",
       "      <td>48.781</td>\n",
       "      <td>170.55</td>\n",
       "      <td>33.81</td>\n",
       "      <td>90.3</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>510.3</td>\n",
       "      <td>15.43</td>\n",
       "      <td>510.35400</td>\n",
       "      <td>459.5</td>\n",
       "      <td>464.4</td>\n",
       "      <td>0.02064</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>34.30</td>\n",
       "      <td>-183.00</td>\n",
       "      <td>491.8</td>\n",
       "      <td>400.2</td>\n",
       "      <td>439.6</td>\n",
       "      <td>352048.133</td>\n",
       "      <td>351911</td>\n",
       "      <td>43.475</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.433921</td>\n",
       "      <td>131.347155</td>\n",
       "      <td>91.6</td>\n",
       "      <td>0.878710</td>\n",
       "      <td>2.534754e+39</td>\n",
       "      <td>8.041233e+41</td>\n",
       "      <td>1.421451e+33</td>\n",
       "      <td>2.707872</td>\n",
       "      <td>2.707826</td>\n",
       "      <td>2.662286</td>\n",
       "      <td>2.666892</td>\n",
       "      <td>-1.685290</td>\n",
       "      <td>-2.761954</td>\n",
       "      <td>-0.602060</td>\n",
       "      <td>0.053078</td>\n",
       "      <td>-2.899629</td>\n",
       "      <td>2.691789</td>\n",
       "      <td>2.602277</td>\n",
       "      <td>2.643058</td>\n",
       "      <td>2.118421</td>\n",
       "      <td>-0.362589</td>\n",
       "      <td>-0.056155</td>\n",
       "      <td>39.403936</td>\n",
       "      <td>41.905323</td>\n",
       "      <td>33.152732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>FRB20210331F</td>\n",
       "      <td>-9999</td>\n",
       "      <td>122.070</td>\n",
       "      <td>72.350</td>\n",
       "      <td>142.57</td>\n",
       "      <td>31.55</td>\n",
       "      <td>135.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>24.28</td>\n",
       "      <td>288.3</td>\n",
       "      <td>50.27</td>\n",
       "      <td>288.42000</td>\n",
       "      <td>237.9</td>\n",
       "      <td>243.1</td>\n",
       "      <td>0.00885</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.02</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>58.00</td>\n",
       "      <td>-88.00</td>\n",
       "      <td>662.7</td>\n",
       "      <td>480.9</td>\n",
       "      <td>564.5</td>\n",
       "      <td>497640.634</td>\n",
       "      <td>492355</td>\n",
       "      <td>47.278</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.175508</td>\n",
       "      <td>213.707304</td>\n",
       "      <td>181.8</td>\n",
       "      <td>4.253481</td>\n",
       "      <td>2.705696e+39</td>\n",
       "      <td>5.318324e+41</td>\n",
       "      <td>2.945764e+33</td>\n",
       "      <td>2.460025</td>\n",
       "      <td>2.459845</td>\n",
       "      <td>2.376394</td>\n",
       "      <td>2.385785</td>\n",
       "      <td>-2.053057</td>\n",
       "      <td>-2.602060</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.785330</td>\n",
       "      <td>-2.301030</td>\n",
       "      <td>2.821317</td>\n",
       "      <td>2.682055</td>\n",
       "      <td>2.751664</td>\n",
       "      <td>2.329819</td>\n",
       "      <td>-0.755704</td>\n",
       "      <td>0.628745</td>\n",
       "      <td>39.432279</td>\n",
       "      <td>41.725775</td>\n",
       "      <td>33.469198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>FRB20210331F</td>\n",
       "      <td>-9999</td>\n",
       "      <td>122.070</td>\n",
       "      <td>72.350</td>\n",
       "      <td>142.57</td>\n",
       "      <td>31.55</td>\n",
       "      <td>135.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>24.28</td>\n",
       "      <td>288.3</td>\n",
       "      <td>50.27</td>\n",
       "      <td>288.42000</td>\n",
       "      <td>237.9</td>\n",
       "      <td>243.1</td>\n",
       "      <td>0.00885</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.02</td>\n",
       "      <td>6.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>47.50</td>\n",
       "      <td>-119.20</td>\n",
       "      <td>578.4</td>\n",
       "      <td>428.0</td>\n",
       "      <td>497.6</td>\n",
       "      <td>497640.634</td>\n",
       "      <td>492355</td>\n",
       "      <td>47.278</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.175508</td>\n",
       "      <td>176.796362</td>\n",
       "      <td>150.4</td>\n",
       "      <td>1.066773</td>\n",
       "      <td>2.385039e+39</td>\n",
       "      <td>4.688039e+41</td>\n",
       "      <td>3.791099e+33</td>\n",
       "      <td>2.460025</td>\n",
       "      <td>2.459845</td>\n",
       "      <td>2.376394</td>\n",
       "      <td>2.385785</td>\n",
       "      <td>-2.053057</td>\n",
       "      <td>-2.602060</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.785330</td>\n",
       "      <td>-2.901702</td>\n",
       "      <td>2.762228</td>\n",
       "      <td>2.631444</td>\n",
       "      <td>2.696880</td>\n",
       "      <td>2.247473</td>\n",
       "      <td>-0.755704</td>\n",
       "      <td>0.028072</td>\n",
       "      <td>39.377495</td>\n",
       "      <td>41.670991</td>\n",
       "      <td>33.578765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>FRB20210426B</td>\n",
       "      <td>-9999</td>\n",
       "      <td>122.070</td>\n",
       "      <td>72.350</td>\n",
       "      <td>142.57</td>\n",
       "      <td>31.55</td>\n",
       "      <td>135.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>12.49</td>\n",
       "      <td>292.8</td>\n",
       "      <td>31.13</td>\n",
       "      <td>288.92000</td>\n",
       "      <td>238.4</td>\n",
       "      <td>243.6</td>\n",
       "      <td>0.00786</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>-8.20</td>\n",
       "      <td>15.00</td>\n",
       "      <td>800.2</td>\n",
       "      <td>613.2</td>\n",
       "      <td>800.2</td>\n",
       "      <td>1872864.206</td>\n",
       "      <td>1866568</td>\n",
       "      <td>45.490</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.176116</td>\n",
       "      <td>219.933602</td>\n",
       "      <td>187.0</td>\n",
       "      <td>4.251283</td>\n",
       "      <td>4.812697e+39</td>\n",
       "      <td>1.191640e+42</td>\n",
       "      <td>2.936170e+33</td>\n",
       "      <td>2.460778</td>\n",
       "      <td>2.466571</td>\n",
       "      <td>2.377306</td>\n",
       "      <td>2.386677</td>\n",
       "      <td>-2.104577</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.204120</td>\n",
       "      <td>0.880814</td>\n",
       "      <td>-2.301030</td>\n",
       "      <td>2.903199</td>\n",
       "      <td>2.787602</td>\n",
       "      <td>2.903199</td>\n",
       "      <td>2.342292</td>\n",
       "      <td>-0.754202</td>\n",
       "      <td>0.628520</td>\n",
       "      <td>39.682389</td>\n",
       "      <td>42.076145</td>\n",
       "      <td>33.467781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>FRB20210426B</td>\n",
       "      <td>-9999</td>\n",
       "      <td>122.070</td>\n",
       "      <td>72.350</td>\n",
       "      <td>142.57</td>\n",
       "      <td>31.55</td>\n",
       "      <td>135.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>12.49</td>\n",
       "      <td>292.8</td>\n",
       "      <td>31.13</td>\n",
       "      <td>288.92000</td>\n",
       "      <td>238.4</td>\n",
       "      <td>243.6</td>\n",
       "      <td>0.00786</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>74.60</td>\n",
       "      <td>-155.00</td>\n",
       "      <td>564.2</td>\n",
       "      <td>447.6</td>\n",
       "      <td>502.5</td>\n",
       "      <td>1872864.206</td>\n",
       "      <td>1866568</td>\n",
       "      <td>45.490</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.176116</td>\n",
       "      <td>137.135070</td>\n",
       "      <td>116.6</td>\n",
       "      <td>4.251283</td>\n",
       "      <td>3.022220e+39</td>\n",
       "      <td>7.483115e+41</td>\n",
       "      <td>7.445711e+33</td>\n",
       "      <td>2.460778</td>\n",
       "      <td>2.466571</td>\n",
       "      <td>2.377306</td>\n",
       "      <td>2.386677</td>\n",
       "      <td>-2.104577</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.204120</td>\n",
       "      <td>0.880814</td>\n",
       "      <td>-2.301030</td>\n",
       "      <td>2.751433</td>\n",
       "      <td>2.650890</td>\n",
       "      <td>2.701136</td>\n",
       "      <td>2.137149</td>\n",
       "      <td>-0.754202</td>\n",
       "      <td>0.628520</td>\n",
       "      <td>39.480326</td>\n",
       "      <td>41.874082</td>\n",
       "      <td>33.871906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>730 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tns_name repeater_name       ra     dec      gl     gb  exp_up  \\\n",
       "0    FRB20180725A         -9999   93.420  67.070  147.29  21.29    30.0   \n",
       "1    FRB20180727A         -9999  197.720  26.420   24.76  85.60    10.4   \n",
       "2    FRB20180729A         -9999  199.400  55.580  115.26  61.16    21.0   \n",
       "3    FRB20180729B         -9999   89.930  56.500  156.90  15.68    21.0   \n",
       "4    FRB20180730A         -9999   57.390  87.190  125.11  25.11   270.0   \n",
       "..            ...           ...      ...     ...     ...    ...     ...   \n",
       "725  FRB20210313E  FRB20201221B  124.199  48.781  170.55  33.81    90.3   \n",
       "726  FRB20210331F         -9999  122.070  72.350  142.57  31.55   135.0   \n",
       "727  FRB20210331F         -9999  122.070  72.350  142.57  31.55   135.0   \n",
       "728  FRB20210426B         -9999  122.070  72.350  142.57  31.55   135.0   \n",
       "729  FRB20210426B         -9999  122.070  72.350  142.57  31.55   135.0   \n",
       "\n",
       "     exp_low  bonsai_snr  bonsai_dm  snr_fitb    dm_fitb  dm_exc_ne2001  \\\n",
       "0    -9999.0       19.20      716.6     33.20  715.80930          644.2   \n",
       "1    -9999.0       10.40      642.1     12.20  642.13400          620.9   \n",
       "2    -9999.0       32.00      108.4    206.60  109.59418           78.8   \n",
       "3    -9999.0       12.40      318.6     22.00  317.22350          223.2   \n",
       "4      214.0       69.50      849.2     89.80  848.90410          789.7   \n",
       "..       ...         ...        ...       ...        ...            ...   \n",
       "725  -9999.0       10.00      510.3     15.43  510.35400          459.5   \n",
       "726    108.0       24.28      288.3     50.27  288.42000          237.9   \n",
       "727    108.0       24.28      288.3     50.27  288.42000          237.9   \n",
       "728    108.0       12.49      292.8     31.13  288.92000          238.4   \n",
       "729    108.0       12.49      292.8     31.13  288.92000          238.4   \n",
       "\n",
       "     dm_exc_ymw16  bc_width  scat_time   flux  fluence  sub_num  width_fitb  \\\n",
       "0           635.4   0.00295   0.001100   1.70     4.10        0    0.000296   \n",
       "1           622.4   0.00295   0.001700   0.58     2.31        0    0.001390   \n",
       "2            86.8   0.00098   0.000157  11.70    17.00        0    0.000100   \n",
       "3           198.8   0.00197   0.000660   0.92     1.20        0    0.000314   \n",
       "4           790.5   0.00492   0.002073   5.20    27.00        0    0.000468   \n",
       "..            ...       ...        ...    ...      ...      ...         ...   \n",
       "725         464.4   0.02064   0.001730   0.25     1.13        0    0.001260   \n",
       "726         243.1   0.00885   0.002500   1.02     6.10        0    0.005000   \n",
       "727         243.1   0.00885   0.002500   1.02     6.10        1    0.001254   \n",
       "728         243.6   0.00786   0.010000   1.60     7.60        0    0.005000   \n",
       "729         243.6   0.00786   0.010000   1.60     7.60        1    0.005000   \n",
       "\n",
       "     sp_idx  sp_run  high_freq  low_freq  peak_freq       chi_sq      dof  \\\n",
       "0     38.20  -45.80      760.1     485.3      607.4   371857.954   371481   \n",
       "1      3.80   -9.20      800.2     400.2      493.3   382969.318   381818   \n",
       "2     16.46  -30.21      692.7     400.2      525.6   264732.041   186953   \n",
       "3     14.50  -14.60      800.2     441.8      657.5   425139.488   421337   \n",
       "4      4.27  -11.31      759.2     400.2      483.5   429165.844   417689   \n",
       "..      ...     ...        ...       ...        ...          ...      ...   \n",
       "725   34.30 -183.00      491.8     400.2      439.6   352048.133   351911   \n",
       "726   58.00  -88.00      662.7     480.9      564.5   497640.634   492355   \n",
       "727   47.50 -119.20      578.4     428.0      497.6   497640.634   492355   \n",
       "728   -8.20   15.00      800.2     613.2      800.2  1872864.206  1866568   \n",
       "729   74.60 -155.00      564.2     447.6      502.5  1872864.206  1866568   \n",
       "\n",
       "     flag_frac  is_repeater  is_pcc_candidate  catalog  redshift   fre_width  \\\n",
       "0        0.403            0                 0     2021  0.640740  450.875425   \n",
       "1        0.387            0                 0     2021  0.614818  645.927163   \n",
       "2        0.399            0                 0     2021  0.002248  293.157605   \n",
       "3        0.323            0                 0     2021  0.157566  414.871625   \n",
       "4        0.329            0                 0     2021  0.802405  647.063272   \n",
       "..         ...          ...               ...      ...       ...         ...   \n",
       "725     43.475            1                 0     2023  0.433921  131.347155   \n",
       "726     47.278            0                 1     2023  0.175508  213.707304   \n",
       "727     47.278            0                 1     2023  0.175508  176.796362   \n",
       "728     45.490            0                 1     2023  0.176116  219.933602   \n",
       "729     45.490            0                 1     2023  0.176116  137.135070   \n",
       "\n",
       "     fre_width_ob  in_duration        energy    luminosity           T_B  \\\n",
       "0           274.8     0.180406  2.827944e+40  1.923870e+43  5.515622e+35   \n",
       "1           400.0     0.860778  1.189571e+40  4.823143e+42  2.622746e+35   \n",
       "2           292.5     0.099776  1.070358e+36  7.383140e+38  4.845901e+32   \n",
       "3           358.4     0.271259  4.966122e+38  4.407270e+41  3.166148e+34   \n",
       "4           359.0     0.259653  2.335510e+41  8.107252e+43  1.508095e+36   \n",
       "..            ...          ...           ...           ...           ...   \n",
       "725          91.6     0.878710  2.534754e+39  8.041233e+41  1.421451e+33   \n",
       "726         181.8     4.253481  2.705696e+39  5.318324e+41  2.945764e+33   \n",
       "727         150.4     1.066773  2.385039e+39  4.688039e+41  3.791099e+33   \n",
       "728         187.0     4.251283  4.812697e+39  1.191640e+42  2.936170e+33   \n",
       "729         116.6     4.251283  3.022220e+39  7.483115e+41  7.445711e+33   \n",
       "\n",
       "     log_dm_fitb  log_bonsai_dm  log_dm_exc_ne2001  log_dm_exc_ymw16  \\\n",
       "0       2.854797       2.855277           2.809021          2.803047   \n",
       "1       2.807626       2.807603           2.793022          2.794070   \n",
       "2       2.039787       2.035029           1.896526          1.938520   \n",
       "3       2.501365       2.503246           2.348694          2.298416   \n",
       "4       2.928859       2.929010           2.897462          2.897902   \n",
       "..           ...            ...                ...               ...   \n",
       "725     2.707872       2.707826           2.662286          2.666892   \n",
       "726     2.460025       2.459845           2.376394          2.385785   \n",
       "727     2.460025       2.459845           2.376394          2.385785   \n",
       "728     2.460778       2.466571           2.377306          2.386677   \n",
       "729     2.460778       2.466571           2.377306          2.386677   \n",
       "\n",
       "     log_bc_width  log_scat_time  log_flux  log_fluence  log_width_fitb  \\\n",
       "0       -2.530178      -2.958607  0.230449     0.612784       -3.528708   \n",
       "1       -2.530178      -2.769551 -0.236572     0.363612       -2.856985   \n",
       "2       -3.008774      -3.802995  1.068186     1.230449       -4.000000   \n",
       "3       -2.705534      -3.180456 -0.036212     0.079181       -3.503070   \n",
       "4       -2.308035      -2.683401  0.716003     1.431364       -3.329754   \n",
       "..            ...            ...       ...          ...             ...   \n",
       "725     -1.685290      -2.761954 -0.602060     0.053078       -2.899629   \n",
       "726     -2.053057      -2.602060  0.008600     0.785330       -2.301030   \n",
       "727     -2.053057      -2.602060  0.008600     0.785330       -2.901702   \n",
       "728     -2.104577      -2.000000  0.204120     0.880814       -2.301030   \n",
       "729     -2.104577      -2.000000  0.204120     0.880814       -2.301030   \n",
       "\n",
       "     log_high_freq  log_low_freq  log_peak_freq  log_fre_width  log_redshift  \\\n",
       "0         2.880871      2.686010       2.783475       2.654057     -0.193318   \n",
       "1         2.903199      2.602277       2.693111       2.810184     -0.211253   \n",
       "2         2.840545      2.602277       2.720655       2.467101     -2.648161   \n",
       "3         2.903199      2.645226       2.817896       2.617914     -0.802538   \n",
       "4         2.880356      2.602277       2.684396       2.810947     -0.095607   \n",
       "..             ...           ...            ...            ...           ...   \n",
       "725       2.691789      2.602277       2.643058       2.118421     -0.362589   \n",
       "726       2.821317      2.682055       2.751664       2.329819     -0.755704   \n",
       "727       2.762228      2.631444       2.696880       2.247473     -0.755704   \n",
       "728       2.903199      2.787602       2.903199       2.342292     -0.754202   \n",
       "729       2.751433      2.650890       2.701136       2.137149     -0.754202   \n",
       "\n",
       "     log_in_duration  log_energy  log_luminosity    log_T_B  \n",
       "0          -0.743748   40.451471       43.284176  35.741595  \n",
       "1          -0.065109   40.075391       42.683330  35.418756  \n",
       "2          -1.000975   36.029529       38.868241  32.685375  \n",
       "3          -0.566616   38.696017       41.644170  34.500531  \n",
       "4          -0.585606   41.368382       43.908874  36.178429  \n",
       "..               ...         ...             ...        ...  \n",
       "725        -0.056155   39.403936       41.905323  33.152732  \n",
       "726         0.628745   39.432279       41.725775  33.469198  \n",
       "727         0.028072   39.377495       41.670991  33.578765  \n",
       "728         0.628520   39.682389       42.076145  33.467781  \n",
       "729         0.628520   39.480326       41.874082  33.871906  \n",
       "\n",
       "[730 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/features_extracted/combined_2021_23_catalog.csv\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "FEATURES = [\n",
    "    \"ra\",\n",
    "    \"snr_fitb\",\n",
    "    \"log_dm_exc_ymw16\",\n",
    "    \"log_bc_width\",\n",
    "    \"log_flux\",\n",
    "    \"log_fluence\",\n",
    "    \"sp_idx\",\n",
    "    \"sp_run\",\n",
    "    \"log_in_duration\",\n",
    "    \"log_peak_freq\",\n",
    "    \"log_fre_width\",\n",
    "    \"log_T_B\",\n",
    "    \"log_energy\",\n",
    "]\n",
    "FEATURE_LABELS = [\n",
    "    \"Right Ascension\",\n",
    "    \"SNR (fitburst)\",\n",
    "    \"Excess DM (YMW16)\",\n",
    "    \"Boxcar width\",\n",
    "    \"Flux\",\n",
    "    \"Fluence\",\n",
    "    \"Spectral index\",\n",
    "    \"Spectral running\",\n",
    "    \"Rest-frame width\",\n",
    "    \"Peak frequency\",\n",
    "    \"Frequency width\",\n",
    "    \"Brightness temperature\",\n",
    "    \"Burst energy\",\n",
    "]\n",
    "X = df[FEATURES]\n",
    "y = df[\"is_repeater\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=(586, 13) y_train.shape=(586,) X_val.shape=(144, 13) y_val.shape=(144,)\n",
      "X_scaled.shape=(730, 13)\n",
      "X_train_scaled.shape=(586, 13) X_val_scaled.shape=(144, 13)\n",
      "Before SMOTE: Counter({0: 410, 1: 176})\n",
      "X_train_scaled_sm.shape=(820, 13) y_train_sm.shape=(820,)\n",
      "After SMOTE: Counter({0: 410, 1: 410})\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "# 1. We split the data into training and validation sets, but make sure that sub-bursts for a given burst are either all in the training set or all in the validation set\n",
    "X_train, X_val, y_train, y_val = get_subburst_preserved_train_test(\n",
    "    df, X, y, test_size=0.2, stratify=True\n",
    ")\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_val = pd.DataFrame(X_val, columns=X.columns)\n",
    "y_train = pd.Series(y_train)\n",
    "y_val = pd.Series(y_val)\n",
    "print(f\"{X_train.shape=} {y_train.shape=} {X_val.shape=} {y_val.shape=}\")\n",
    "\n",
    "# 2. We scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_scaled = scaler.transform(X)\n",
    "print(f\"{X_scaled.shape=}\\n{X_train_scaled.shape=} {X_val_scaled.shape=}\")\n",
    "\n",
    "# 3. We oversample the training set to balance the classes\n",
    "print(f\"Before SMOTE: {Counter(y_train)}\")\n",
    "sm = SMOTE()\n",
    "X_train_scaled_sm, y_train_sm = sm.fit_resample(X_train_scaled, y_train)\n",
    "print(f\"{X_train_scaled_sm.shape=} {y_train_sm.shape=}\")\n",
    "print(f\"After SMOTE: {Counter(y_train_sm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 100\n",
    "optimised_models = []\n",
    "models_info = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'DecisionTreeClassifier', 'params': {'min_samples_split': 20, 'min_samples_leaf': 2, 'criterion': 'gini'}, 'll_score': 1.7776479181884588}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def dt_objective(trial):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    classifier_obj = DecisionTreeClassifier(\n",
    "        min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 32),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 32),\n",
    "        criterion=trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "    classifier_obj.fit(X_train_scaled_sm, y_train_sm)\n",
    "    predictions = classifier_obj.predict(X_val_scaled)\n",
    "    ll_score = lee_liu_score(y_val, predictions)\n",
    "    return ll_score\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(dt_objective, n_trials=NUM_TRIALS)\n",
    "best_params = study.best_params\n",
    "dt = DecisionTreeClassifier(**best_params, random_state=RANDOM_SEED)\n",
    "dt.fit(X_train_scaled_sm, y_train_sm)\n",
    "optimised_models.append(dt)\n",
    "data = {\n",
    "    \"model\": \"DecisionTreeClassifier\",\n",
    "    \"params\": best_params,\n",
    "    \"ll_score\": study.best_value,\n",
    "}\n",
    "print(data)\n",
    "models_info.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'RandomForestClassifier', 'params': {'n_estimators': 245, 'min_samples_split': 21, 'min_samples_leaf': 10, 'criterion': 'entropy'}, 'll_score': 2.0572476939541677}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def rf_objective(trial):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    classifier_obj = RandomForestClassifier(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 32),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 32),\n",
    "        criterion=trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "    classifier_obj.fit(X_train_scaled_sm, y_train_sm)\n",
    "    predictions = classifier_obj.predict(X_val_scaled)\n",
    "    ll_score = lee_liu_score(y_val, predictions)\n",
    "    return ll_score\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(rf_objective, n_trials=NUM_TRIALS)\n",
    "best_params = study.best_params\n",
    "\n",
    "rf = RandomForestClassifier(**best_params, random_state=RANDOM_SEED)\n",
    "rf.fit(X_train_scaled_sm, y_train_sm)\n",
    "optimised_models.append(rf)\n",
    "data = {\n",
    "    \"model\": \"RandomForestClassifier\",\n",
    "    \"params\": best_params,\n",
    "    \"ll_score\": study.best_value,\n",
    "}\n",
    "print(data)\n",
    "models_info.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'SVC', 'params': {'C': 0.053370327626039576, 'degree': 2}, 'll_score': 2.2439737034331633}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def svm_objective(trial):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    classifier_obj = SVC(\n",
    "        C=trial.suggest_float(\"C\", 1e-2, 1e2, log=True),\n",
    "        degree=trial.suggest_int(\"degree\", 1, 8),\n",
    "        kernel=\"linear\",  # fix to linear so we can access coefficients later\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "    classifier_obj.fit(X_train_scaled_sm, y_train_sm)\n",
    "    predictions = classifier_obj.predict(X_val_scaled)\n",
    "    ll_score = lee_liu_score(y_val, predictions)\n",
    "    return ll_score\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(svm_objective, n_trials=NUM_TRIALS)\n",
    "best_params = study.best_params\n",
    "\n",
    "svm = SVC(**best_params, kernel=\"linear\", random_state=RANDOM_SEED)\n",
    "svm.fit(X_train_scaled_sm, y_train_sm)\n",
    "optimised_models.append(svm)\n",
    "data = {\"model\": \"SVC\", \"params\": best_params, \"ll_score\": study.best_value}\n",
    "print(data)\n",
    "models_info.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'AdaBoostClassifier', 'params': {'n_estimators': 379, 'learning_rate': 0.2799743084246729, 'algorithm': 'SAMME.R'}, 'll_score': 2.4371881945199942}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def adaboost_objective(trial):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    classifier_obj = AdaBoostClassifier(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-3, 1),\n",
    "        algorithm=trial.suggest_categorical(\"algorithm\", [\"SAMME\", \"SAMME.R\"]),\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "    classifier_obj.fit(X_train_scaled_sm, y_train_sm)\n",
    "    predictions = classifier_obj.predict(X_val_scaled)\n",
    "    ll_score = lee_liu_score(y_val, predictions)\n",
    "    return ll_score\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(adaboost_objective, n_trials=NUM_TRIALS)\n",
    "best_params = study.best_params\n",
    "\n",
    "adaboost = AdaBoostClassifier(**best_params, random_state=RANDOM_SEED)\n",
    "adaboost.fit(X_train_scaled_sm, y_train_sm)\n",
    "optimised_models.append(adaboost)\n",
    "data = {\n",
    "    \"model\": \"AdaBoostClassifier\",\n",
    "    \"params\": best_params,\n",
    "    \"ll_score\": study.best_value,\n",
    "}\n",
    "print(data)\n",
    "models_info.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'LGBMClassifier', 'params': {'n_estimators': 314, 'learning_rate': 0.7634745502856656, 'subsample': 0.5517416382671432, 'colsample_bytree': 0.8748572996659076}, 'll_score': 2.4067619743295414}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def lgbm_objective(trial):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    classifier_obj = LGBMClassifier(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-3, 1, log=True),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        random_state=RANDOM_SEED,\n",
    "        verbosity=-1,\n",
    "    )\n",
    "    classifier_obj.fit(X_train_scaled_sm, y_train_sm)\n",
    "    predictions = classifier_obj.predict(X_val_scaled)\n",
    "    ll_score = lee_liu_score(y_val, predictions)\n",
    "    return ll_score\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(lgbm_objective, n_trials=NUM_TRIALS)\n",
    "best_params = study.best_params\n",
    "\n",
    "lightgbm = LGBMClassifier(**best_params, random_state=RANDOM_SEED, verbosity=-1)\n",
    "lightgbm.fit(X_train_scaled_sm, y_train_sm)\n",
    "optimised_models.append(lightgbm)\n",
    "data = {\"model\": \"LGBMClassifier\", \"params\": best_params, \"ll_score\": study.best_value}\n",
    "print(data)\n",
    "models_info.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'XGBClassifier', 'params': {'n_estimators': 472, 'eta': 4.463589298990465, 'gamma': 0.015812457773552488, 'min_child_weight': 0.0013235039876917161, 'max_delta_step': 0.02148492608287815, 'max_leaves': 165, 'max_bin': 81, 'subsample': 0.8088819609029114, 'colsample_bytree': 0.4255638819241213}, 'll_score': 2.527100073046019}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def xgb_objective(trial):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    classifier_obj = xgb.XGBClassifier(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        eta=trial.suggest_float(\"eta\", 1e-3, 1e1, log=True),\n",
    "        gamma=trial.suggest_float(\"gamma\", 1e-3, 1e1, log=True),\n",
    "        min_child_weight=trial.suggest_float(\"min_child_weight\", 1e-3, 1e1, log=True),\n",
    "        max_delta_step=trial.suggest_float(\"max_delta_step\", 1e-3, 1e1, log=True),\n",
    "        max_leaves=trial.suggest_int(\"max_leaves\", 2, 256),\n",
    "        max_bin=trial.suggest_int(\"max_bin\", 2, 256),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "    classifier_obj.fit(X_train_scaled_sm, y_train_sm)\n",
    "    predictions = classifier_obj.predict(X_val_scaled)\n",
    "    ll_score = lee_liu_score(y_val, predictions)\n",
    "\n",
    "    return ll_score\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(xgb_objective, n_trials=NUM_TRIALS)\n",
    "best_params = study.best_params\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(**best_params)\n",
    "xgb_model.fit(X_train_scaled_sm, y_train_sm)\n",
    "optimised_models.append(xgb_model)\n",
    "data = {\"model\": \"XGBClassifier\", \"params\": best_params, \"ll_score\": study.best_value}\n",
    "print(data)\n",
    "models_info.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.148492608287815"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.02148492608287815 / (10 ** (-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'LogisticRegression', 'params': {'tol': 5.6115164153345e-05, 'C': 63.512210106407046, 'solver': 'liblinear', 'max_iter': 162}, 'll_score': 2.071360341630612}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def lr_objective(trial):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    classifier_obj = LogisticRegression(\n",
    "        tol=trial.suggest_float(\"tol\", 1e-5, 1e-3, log=True),\n",
    "        C=trial.suggest_float(\"C\", 1e-2, 1e2, log=True),\n",
    "        solver=trial.suggest_categorical(\"solver\", [\"liblinear\", \"newton-cholesky\"]),\n",
    "        max_iter=trial.suggest_int(\"max_iter\", 100, 500),\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "    classifier_obj.fit(X_train_scaled_sm, y_train_sm)\n",
    "    predictions = classifier_obj.predict(X_val_scaled)\n",
    "    ll_score = lee_liu_score(y_val, predictions)\n",
    "    return ll_score\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(lr_objective, n_trials=NUM_TRIALS)\n",
    "best_params = study.best_params\n",
    "\n",
    "lr = LogisticRegression(**best_params)\n",
    "lr.fit(X_train_scaled_sm, y_train_sm)\n",
    "optimised_models.append(lr)\n",
    "data = {\n",
    "    \"model\": \"LogisticRegression\",\n",
    "    \"params\": best_params,\n",
    "    \"ll_score\": study.best_value,\n",
    "}\n",
    "print(data)\n",
    "models_info.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'LinearDiscriminantAnalysis', 'params': {'solver': 'svd', 'store_covariance': False, 'tol': 0.000462258900102083}, 'll_score': 2.2439737034331633}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def lda_objective(trial):\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    classifier_obj = LinearDiscriminantAnalysis(\n",
    "        solver=trial.suggest_categorical(\"solver\", [\"svd\", \"lsqr\", \"eigen\"]),\n",
    "        # Only used if the solver is SVD\n",
    "        store_covariance=trial.suggest_categorical(\"store_covariance\", [True, False]),\n",
    "        tol=trial.suggest_float(\"tol\", 1e-5, 1e-3, log=True),\n",
    "    )\n",
    "    if classifier_obj.solver != \"svd\":\n",
    "        classifier_obj.shrinkage = trial.suggest_float(\"shrinkage\", 0.0, 1.0)\n",
    "\n",
    "    classifier_obj.fit(X_train_scaled_sm, y_train_sm)\n",
    "    predictions = classifier_obj.predict(X_val_scaled)\n",
    "    ll_score = lee_liu_score(y_val, predictions)\n",
    "    return ll_score\n",
    "\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(lda_objective, n_trials=NUM_TRIALS)\n",
    "best_params = study.best_params\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(**best_params)\n",
    "lda.fit(X_train_scaled_sm, y_train_sm)\n",
    "optimised_models.append(lda)\n",
    "data = {\n",
    "    \"model\": \"LinearDiscriminantAnalysis\",\n",
    "    \"params\": best_params,\n",
    "    \"ll_score\": study.best_value,\n",
    "}\n",
    "print(data)\n",
    "models_info.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>ll_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_samples_split': 20, 'min_samples_leaf': ...</td>\n",
       "      <td>1.777648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'n_estimators': 245, 'min_samples_split': 21,...</td>\n",
       "      <td>2.057248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 0.053370327626039576, 'degree': 2}</td>\n",
       "      <td>2.243974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'n_estimators': 379, 'learning_rate': 0.27997...</td>\n",
       "      <td>2.437188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'n_estimators': 314, 'learning_rate': 0.76347...</td>\n",
       "      <td>2.406762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'n_estimators': 472, 'eta': 4.463589298990465...</td>\n",
       "      <td>2.527100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'tol': 5.6115164153345e-05, 'C': 63.512210106...</td>\n",
       "      <td>2.071360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'solver': 'svd', 'store_covariance': False, '...</td>\n",
       "      <td>2.243974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  \\\n",
       "0      DecisionTreeClassifier   \n",
       "1      RandomForestClassifier   \n",
       "2                         SVC   \n",
       "3          AdaBoostClassifier   \n",
       "4              LGBMClassifier   \n",
       "5               XGBClassifier   \n",
       "6          LogisticRegression   \n",
       "7  LinearDiscriminantAnalysis   \n",
       "\n",
       "                                              params  ll_score  \n",
       "0  {'min_samples_split': 20, 'min_samples_leaf': ...  1.777648  \n",
       "1  {'n_estimators': 245, 'min_samples_split': 21,...  2.057248  \n",
       "2           {'C': 0.053370327626039576, 'degree': 2}  2.243974  \n",
       "3  {'n_estimators': 379, 'learning_rate': 0.27997...  2.437188  \n",
       "4  {'n_estimators': 314, 'learning_rate': 0.76347...  2.406762  \n",
       "5  {'n_estimators': 472, 'eta': 4.463589298990465...  2.527100  \n",
       "6  {'tol': 5.6115164153345e-05, 'C': 63.512210106...  2.071360  \n",
       "7  {'solver': 'svd', 'store_covariance': False, '...  2.243974  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df = pd.DataFrame(models_info)\n",
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to analyse the models with greater confidence, we retrain each of them with their ideal hyperparameters on randomized training sets a 1000 times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n",
      "Trial 100\n",
      "Trial 200\n",
      "Trial 300\n",
      "Trial 400\n",
      "Trial 500\n",
      "Trial 600\n",
      "Trial 700\n",
      "Trial 800\n",
      "Trial 900\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "models_recalls = [[] for _ in range(len(optimised_models))]\n",
    "models_llscores = [[] for _ in range(len(optimised_models))]\n",
    "candidates = {}\n",
    "\n",
    "for j in range(1000):\n",
    "    if j % 100 == 0:\n",
    "        print(f\"Trial {j}\")\n",
    "    X_train, X_val, y_train, y_val = get_subburst_preserved_train_test(\n",
    "        df, X, y, test_size=0.2, stratify=True\n",
    "    )\n",
    "    X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "    X_val = pd.DataFrame(X_val, columns=X.columns)\n",
    "    y_train = pd.Series(y_train)\n",
    "    y_val = pd.Series(y_val)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    sm = SMOTE()\n",
    "    X_train_scaled_sm, y_train_sm = sm.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    for i, model in enumerate(optimised_models):\n",
    "        predictions = model.predict(X_val_scaled)\n",
    "        recall = recall_score(y_val, predictions)\n",
    "        ll_score = lee_liu_score(y_val, predictions)\n",
    "        models_recalls[i].append(recall)\n",
    "        models_llscores[i].append(ll_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>ll_score</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>llscore_mean</th>\n",
       "      <th>llscore_std</th>\n",
       "      <th>fittime_mean</th>\n",
       "      <th>fittime_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 0.053370327626039576, 'degree': 2}</td>\n",
       "      <td>2.243974</td>\n",
       "      <td>0.844602</td>\n",
       "      <td>0.056898</td>\n",
       "      <td>2.069516</td>\n",
       "      <td>0.217661</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>{'solver': 'svd', 'store_covariance': False, '...</td>\n",
       "      <td>2.243974</td>\n",
       "      <td>0.843165</td>\n",
       "      <td>0.057591</td>\n",
       "      <td>2.094140</td>\n",
       "      <td>0.219028</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'tol': 5.6115164153345e-05, 'C': 63.512210106...</td>\n",
       "      <td>2.071360</td>\n",
       "      <td>0.833235</td>\n",
       "      <td>0.060790</td>\n",
       "      <td>2.057242</td>\n",
       "      <td>0.224674</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'n_estimators': 245, 'min_samples_split': 21,...</td>\n",
       "      <td>2.057248</td>\n",
       "      <td>0.823439</td>\n",
       "      <td>0.060648</td>\n",
       "      <td>2.081527</td>\n",
       "      <td>0.220618</td>\n",
       "      <td>0.302034</td>\n",
       "      <td>0.025809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>{'n_estimators': 379, 'learning_rate': 0.27997...</td>\n",
       "      <td>2.437188</td>\n",
       "      <td>0.812825</td>\n",
       "      <td>0.065727</td>\n",
       "      <td>2.089640</td>\n",
       "      <td>0.239789</td>\n",
       "      <td>0.436932</td>\n",
       "      <td>0.019913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>{'n_estimators': 472, 'eta': 4.463589298990465...</td>\n",
       "      <td>2.527100</td>\n",
       "      <td>0.808910</td>\n",
       "      <td>0.063510</td>\n",
       "      <td>2.211336</td>\n",
       "      <td>0.250621</td>\n",
       "      <td>1.940661</td>\n",
       "      <td>2.417792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>{'n_estimators': 314, 'learning_rate': 0.76347...</td>\n",
       "      <td>2.406762</td>\n",
       "      <td>0.798540</td>\n",
       "      <td>0.065712</td>\n",
       "      <td>2.153348</td>\n",
       "      <td>0.248306</td>\n",
       "      <td>0.153323</td>\n",
       "      <td>0.028639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{'min_samples_split': 20, 'min_samples_leaf': ...</td>\n",
       "      <td>1.777648</td>\n",
       "      <td>0.695889</td>\n",
       "      <td>0.085825</td>\n",
       "      <td>1.602646</td>\n",
       "      <td>0.280352</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.006386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  \\\n",
       "2                         SVC   \n",
       "7  LinearDiscriminantAnalysis   \n",
       "6          LogisticRegression   \n",
       "1      RandomForestClassifier   \n",
       "3          AdaBoostClassifier   \n",
       "5               XGBClassifier   \n",
       "4              LGBMClassifier   \n",
       "0      DecisionTreeClassifier   \n",
       "\n",
       "                                              params  ll_score  recall_mean  \\\n",
       "2           {'C': 0.053370327626039576, 'degree': 2}  2.243974     0.844602   \n",
       "7  {'solver': 'svd', 'store_covariance': False, '...  2.243974     0.843165   \n",
       "6  {'tol': 5.6115164153345e-05, 'C': 63.512210106...  2.071360     0.833235   \n",
       "1  {'n_estimators': 245, 'min_samples_split': 21,...  2.057248     0.823439   \n",
       "3  {'n_estimators': 379, 'learning_rate': 0.27997...  2.437188     0.812825   \n",
       "5  {'n_estimators': 472, 'eta': 4.463589298990465...  2.527100     0.808910   \n",
       "4  {'n_estimators': 314, 'learning_rate': 0.76347...  2.406762     0.798540   \n",
       "0  {'min_samples_split': 20, 'min_samples_leaf': ...  1.777648     0.695889   \n",
       "\n",
       "   recall_std  llscore_mean  llscore_std  fittime_mean  fittime_std  \n",
       "2    0.056898      2.069516     0.217661      0.004148     0.000518  \n",
       "7    0.057591      2.094140     0.219028      0.001091     0.000217  \n",
       "6    0.060790      2.057242     0.224674      0.001140     0.000237  \n",
       "1    0.060648      2.081527     0.220618      0.302034     0.025809  \n",
       "3    0.065727      2.089640     0.239789      0.436932     0.019913  \n",
       "5    0.063510      2.211336     0.250621      1.940661     2.417792  \n",
       "4    0.065712      2.153348     0.248306      0.153323     0.028639  \n",
       "0    0.085825      1.602646     0.280352      0.007979     0.006386  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_recalls_mean = [np.mean(recalls) for recalls in models_recalls]\n",
    "models_recalls_std = [np.std(recalls) for recalls in models_recalls]\n",
    "models_llscores_mean = [np.mean(llscores) for llscores in models_llscores]\n",
    "models_llscores_std = [np.std(llscores) for llscores in models_llscores]\n",
    "\n",
    "models_df[\"recall_mean\"] = models_recalls_mean\n",
    "models_df[\"recall_std\"] = models_recalls_std\n",
    "models_df[\"llscore_mean\"] = models_llscores_mean\n",
    "models_df[\"llscore_std\"] = models_llscores_std\n",
    "\n",
    "sorted_models = models_df.sort_values(\"recall_mean\", ascending=False)\n",
    "NUM_SELECTED_MODELS = 3\n",
    "TOP_MODEL_INDICES = list(sorted_models[:NUM_SELECTED_MODELS].index)\n",
    "TOP_MODELS = [optimised_models[i] for i in TOP_MODEL_INDICES]\n",
    "TOP_MODEL_NAMES = sorted_models[\"model\"].values[:NUM_SELECTED_MODELS]\n",
    "sorted_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.to_csv(\"data/supervised_models_optimised.csv\", index=False)\n",
    "models_df[\n",
    "    [\n",
    "        \"model\",\n",
    "        \"recall_mean\",\n",
    "        \"recall_std\",\n",
    "        \"llscore_mean\",\n",
    "        \"llscore_std\",\n",
    "    ]\n",
    "].sort_values(\"recall_mean\", ascending=False).to_latex(\n",
    "    \"tables/supervised_models_optimised.tex\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
